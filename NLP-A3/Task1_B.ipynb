{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgX0rnACZYS1"
      },
      "source": [
        "## Setup - 1B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhqE2PMCavsu"
      },
      "source": [
        "You are required to make use of the Sentence-BERT model\n",
        "(https://arxiv.org/pdf/1908.10084.pdf) and the SentenceTransformers framework\n",
        "(Sentence-Transformers). For this setup, make use of the Sentence-BERT model to\n",
        "encode the sentences and determine the cosine similarity between these embeddings\n",
        "for the validation set. Report the required evaluation metric on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs0wL8dxWEOC"
      },
      "outputs": [],
      "source": [
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHQSIlCaWTSg"
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siAvNrxkaCLk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "train_df = pd.read_csv('./A3_task1_data_files/train.csv', sep='\\t')\n",
        "val_df = pd.read_csv('./A3_task1_data_files/dev.csv', sep='\\t')\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train_df['score'] = scaler.fit_transform(train_df[['score']])\n",
        "val_df['score'] = scaler.fit_transform(val_df[['score']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpZOXCj6aId1"
      },
      "outputs": [],
      "source": [
        "# train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZF3N_tGWEKx",
        "outputId": "1ea82bf4-d90d-4f0f-d5e7-74f9a729d217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation coefficient (Pearson correlation) between predicted similarities and actual scores: 0.6379508453621849\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "model = SentenceTransformer(\"distilbert-base-nli-mean-tokens\")\n",
        "val_embeddings = []\n",
        "for _, row in val_df.iterrows():\n",
        "    if pd.notnull(row['sentence1']) and pd.notnull(row['sentence2']):  # Check for missing values\n",
        "        sentence1_embedding = model.encode(row['sentence1'], convert_to_tensor=True)\n",
        "        sentence2_embedding = model.encode(row['sentence2'], convert_to_tensor=True)\n",
        "        val_embeddings.append((sentence1_embedding, sentence2_embedding))\n",
        "\n",
        "# Calculate cosine similarity between embeddings\n",
        "cosine_similarities = []\n",
        "for embedding_pair in val_embeddings:\n",
        "    cosine_similarities.append(cosine_similarity(embedding_pair[0].unsqueeze(0), embedding_pair[1].unsqueeze(0)).item())\n",
        "\n",
        "correlation_coefficient = val_df['score'].corr(pd.Series(cosine_similarities))\n",
        "print(\"Correlation coefficient (Pearson correlation) between predicted similarities and actual scores:\", correlation_coefficient)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A Pearson correlation coefficient of 0.6379508453621849 indicates a moderately strong positive linear relationship between the predicted similarities and the actual scores"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
