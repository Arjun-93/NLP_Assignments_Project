{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoders:\n",
    " - https://huggingface.co/monsoon-nlp/hindi-bert\n",
    " - https://huggingface.co/flax-community/roberta-hindi\n",
    " - https://huggingface.co/vasista22/whisper-hindi-small\n",
    " \n",
    "Decoders:\n",
    "- https://huggingface.co/csebuetnlp/mT5_m2o_hindi_crossSum\n",
    "- https://huggingface.co/docs/transformers/model_doc/openai-gpt\n",
    "- https://huggingface.co/docs/transformers/model_doc/ctrl\n",
    "- https://huggingface.co/docs/transformers/model_doc/gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import EncoderDecoderModel, AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"monsoon-nlp/hindi-bert\")\n",
    "# model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"monsoon-nlp/hindi-bert\", \"gpt2\")\n",
    "\n",
    "# model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "# model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# # a hindi sentence\n",
    "# input_ids = tokenizer(\n",
    "#     'भारतीय राष्ट्रीय कांग्रेस के अध्यक्ष राहुल गांधी ने शनिवार को कहा कि भारतीय जनता पार्टी ने देश को एक दशक में वापस ले जाया है।',\n",
    "#     return_tensors=\"pt\",\n",
    "# ).input_ids\n",
    "\n",
    "# labels = tokenizer(\n",
    "#     'राहुल गांधी ने कहा कि भारतीय जनता पार्टी ने देश को एक दशक में वापस ले जाया है।', return_tensors=\"pt\",\n",
    "# ).input_ids\n",
    "\n",
    "# # the forward function automatically creates the correct decoder_input_ids\n",
    "# outputs = model(input_ids=input_ids, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = model.generate(input_ids, decoder_start_token_id=model.config.decoder_start_token_id)\n",
    "# outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer2 = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "# tokenizer2.decode(outputs[0], skip_special_tokens=True, predict_with_generate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21225, 4) (3000, 3)\n",
      "(18041, 4) (3184, 4) (3000, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_df = pd.read_csv('/raid/home/dhruv/pankaji/NLP_PROJECT/Data/HindiNews_test.txt')\n",
    "train_df = pd.read_csv('/raid/home/dhruv/pankaji/NLP_PROJECT/Data/hindi_train.txt')\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "train_val_split = 0.15\n",
    "train_df, val_df = train_test_split(train_df, test_size=train_val_split, random_state=42)\n",
    "print(train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8713</th>\n",
       "      <td>hindi_2023_train_8713</td>\n",
       "      <td>प्रोडक्शन के लिए एम्ब्रेयर और सुखोई की बातचीत ...</td>\n",
       "      <td>india looks partner sukhoi embraer to manufact...</td>\n",
       "      <td>भारत सरकार दूर-दराज इलाकों से बेहतर एयर कनेक्ट...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19043</th>\n",
       "      <td>hindi_2022_9186</td>\n",
       "      <td>UP: भदोही में नशे में धुत युवक ने महात्मा गांध...</td>\n",
       "      <td>जिसके बाद कांग्रेस कार्यकर्ता एकत्रित होकर गां...</td>\n",
       "      <td>भदोहीः उत्तर प्रदेश के भदोही में बीती शनिवार र...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17257</th>\n",
       "      <td>hindi_2022_7400</td>\n",
       "      <td>भारत के इस क्षेत्र में नहीं है Coronavirus का ...</td>\n",
       "      <td>भारत में कोविड-19 के मामले 97.35 लाख के पार चल...</td>\n",
       "      <td>कोच्चि: भारत में कोविड-19 के मामले 97.35 लाख क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>hindi_2023_train_3156</td>\n",
       "      <td>12वीं में पासिंग परसेंटेज के आधार पर परीक्षा म...</td>\n",
       "      <td>NEET 2024 - No Minimum Marks Needed For NEET. ...</td>\n",
       "      <td>12वीं के बाद मेडिकल की पढ़ाई करने वाले छात्रों ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15583</th>\n",
       "      <td>hindi_2022_5726</td>\n",
       "      <td>उत्तर प्रदेश में कोरोना वायरस से 17 और मौतें, ...</td>\n",
       "      <td>उत्‍तर प्रदेश में शुक्रवार को कोरोना वायरस संक...</td>\n",
       "      <td>लखनऊ: उत्‍तर प्रदेश में शुक्रवार को कोरोना वाय...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Id  \\\n",
       "8713   hindi_2023_train_8713   \n",
       "19043        hindi_2022_9186   \n",
       "17257        hindi_2022_7400   \n",
       "3156   hindi_2023_train_3156   \n",
       "15583        hindi_2022_5726   \n",
       "\n",
       "                                                 Heading  \\\n",
       "8713   प्रोडक्शन के लिए एम्ब्रेयर और सुखोई की बातचीत ...   \n",
       "19043  UP: भदोही में नशे में धुत युवक ने महात्मा गांध...   \n",
       "17257  भारत के इस क्षेत्र में नहीं है Coronavirus का ...   \n",
       "3156   12वीं में पासिंग परसेंटेज के आधार पर परीक्षा म...   \n",
       "15583  उत्तर प्रदेश में कोरोना वायरस से 17 और मौतें, ...   \n",
       "\n",
       "                                                 Summary  \\\n",
       "8713   india looks partner sukhoi embraer to manufact...   \n",
       "19043  जिसके बाद कांग्रेस कार्यकर्ता एकत्रित होकर गां...   \n",
       "17257  भारत में कोविड-19 के मामले 97.35 लाख के पार चल...   \n",
       "3156   NEET 2024 - No Minimum Marks Needed For NEET. ...   \n",
       "15583  उत्‍तर प्रदेश में शुक्रवार को कोरोना वायरस संक...   \n",
       "\n",
       "                                                 Article  \n",
       "8713   भारत सरकार दूर-दराज इलाकों से बेहतर एयर कनेक्ट...  \n",
       "19043  भदोहीः उत्तर प्रदेश के भदोही में बीती शनिवार र...  \n",
       "17257  कोच्चि: भारत में कोविड-19 के मामले 97.35 लाख क...  \n",
       "3156   12वीं के बाद मेडिकल की पढ़ाई करने वाले छात्रों ...  \n",
       "15583  लखनऊ: उत्‍तर प्रदेश में शुक्रवार को कोरोना वाय...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/raid/home/dhruv/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import EncoderDecoderModel, AutoTokenizer, AutoModelForCausalLM,AutoModelForSeq2SeqLM, MT5ForConditionalGeneration\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/mT5_m2o_hindi_crossSum\") #\"aashay96/indic-gpt\"\n",
    "#model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"ai4bharat/IndicBART\",\"facebook/mbart-large-en-ro\" )\n",
    "\n",
    "\n",
    "decoder_model = MT5ForConditionalGeneration.from_pretrained(\"csebuetnlp/mT5_m2o_hindi_crossSum\").get_decoder()\n",
    "#decoder_model.enc_to_dec_proj=torch.nn.Linear(768, len(tokenizer))\n",
    "#decoder_model.enc_to_dec_proj.name = \"lm_head\"\n",
    "device = torch.device('cuda:6' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "encoder_model =  AutoModelForSeq2SeqLM.from_pretrained(\"csebuetnlp/mT5_m2o_hindi_crossSum\").get_encoder()\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained(encoder_model=encoder_model, decoder_pretrained_model_name_or_path=\"ai4bharat/IndicBART\")\n",
    "model.config.decoder_start_token_id = tokenizer.pad_token_id#tokenizer.cls_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "tokenizer.add_tokens([\"<sum>\"], special_tokens=True )\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "train = iter(train_df['Heading'].iloc[i]+train_df['Article'].iloc[i] for i in range(len(train_df)))\n",
    "new_tokenizer = tokenizer.train_new_from_iterator(train, vocab_size=10000)\n",
    "new_tokens = set(new_tokenizer.vocab) - set(tokenizer.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8170"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(list(new_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(258271, 768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.resize_token_embeddings(len(tokenizer))\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "model.encoder.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoderModel(\n",
       "  (encoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(258271, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): MBartForCausalLM(\n",
       "    (model): MBartDecoderWrapper(\n",
       "      (decoder): MBartDecoder(\n",
       "        (embed_tokens): Embedding(258271, 1024)\n",
       "        (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x MBartDecoderLayer(\n",
       "            (self_attn): MBartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): GELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MBartAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=1024, out_features=258271, bias=False)\n",
       "  )\n",
       "  (enc_to_dec_proj): Linear(in_features=768, out_features=1024, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    }
   ],
   "source": [
    "def train(model, tokenizer, train_df, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    batch = 0\n",
    "    batch_loss = 0\n",
    "    batch_size = 1000\n",
    "    for i, row in train_df.iterrows():\n",
    "        input = tokenizer(\"<sum>\"+row['Heading']+row[\"Article\"], return_tensors=\"pt\")\n",
    "        input_ids = input.input_ids.to(device)\n",
    "        attention_mask = input.attention_mask.to(device)\n",
    "        labels = tokenizer(row['Summary'], return_tensors=\"pt\")\n",
    "        labels_input_ids = labels.input_ids.to(device)\n",
    "        labels_attention_mask = labels.attention_mask.to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask,  labels=labels_input_ids, decoder_attention_mask=labels_attention_mask)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        batch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        batch += 1\n",
    "        if batch % batch_size == 0:\n",
    "            print(f\"Batch {batch} Loss: {batch_loss / batch_size}\")\n",
    "            batch_loss = 0\n",
    "    print(f\"Training Loss: {total_loss / len(train_df)}\")\n",
    "        \n",
    "\n",
    "def evaluate(model, tokenizer, val_df):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for i, row in val_df.iterrows():\n",
    "        input = tokenizer(\"<sum>\"+row['Heading']+row[\"Article\"], return_tensors=\"pt\")\n",
    "        input_ids = input.input_ids.to(device)\n",
    "        attention_mask = input.attention_mask.to(device)\n",
    "        labels = tokenizer(row['Summary'], return_tensors=\"pt\")\n",
    "        labels_input_ids = labels.input_ids.to(device)\n",
    "        labels_attention_mask = labels.attention_mask.to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask,  labels=labels_input_ids, decoder_attention_mask=labels_attention_mask)\n",
    "        total_loss += outputs.loss.item()\n",
    "    print(f\"Validation Loss: {total_loss / len(val_df)}\")\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    train(model, tokenizer, train_df, optimizer)\n",
    "    evaluate(model, tokenizer, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HindiNews_test_6\n",
      "करियर बेस्ट पारी में मंधाना ने जमाए दादा जैसे चौके-छक्के, 87 रन बनाए\n",
      "torch.Size([1, 23])\n",
      "tensor([[     0,    364, 267182,  69670, 264657,    331,  15164, 322946, 264657,\n",
      "            259,    280,    581, 306873,    259,    272,    581, 306873,    259,\n",
      "            296,      2]], device='cuda:6')\n",
      "Summary: Boll ywoo d Actressoo l Update n Update ;\n"
     ]
    }
   ],
   "source": [
    "head_text = test_df['Heading'][12]\n",
    "article_text = test_df[\"Article\"][12]\n",
    "print(test_df['id'][6])\n",
    "print(text)\n",
    "input_ids = tokenizer(\"<sum>\"+text, return_tensors=\"pt\", truncation=True).input_ids.to(device)\n",
    "print(input_ids.shape)\n",
    "\n",
    "outputs = model.generate(input_ids, decoder_start_token_id=model.config.decoder_start_token_id, num_beams=4)\n",
    "print(outputs)\n",
    "# tokenizer2\n",
    "summary = tokenizer.decode(outputs[0], skip_special_tokens=True, predict_with_generate=True)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Article', 'Heading'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"Article\"].iloc[3]\n",
    "test_df[\"Heading\"].iloc[3]\n",
    "test_df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
