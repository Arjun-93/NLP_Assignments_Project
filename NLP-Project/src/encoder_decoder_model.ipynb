{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoders:\n",
    " - https://huggingface.co/monsoon-nlp/hindi-bert\n",
    " - https://huggingface.co/flax-community/roberta-hindi\n",
    " - https://huggingface.co/vasista22/whisper-hindi-small\n",
    " \n",
    "Decoders:\n",
    "- https://huggingface.co/csebuetnlp/mT5_m2o_hindi_crossSum\n",
    "- https://huggingface.co/docs/transformers/model_doc/openai-gpt\n",
    "- https://huggingface.co/docs/transformers/model_doc/ctrl\n",
    "- https://huggingface.co/docs/transformers/model_doc/gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import EncoderDecoderModel, AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"monsoon-nlp/hindi-bert\")\n",
    "# model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"monsoon-nlp/hindi-bert\", \"gpt2\")\n",
    "\n",
    "# model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "# model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# # a hindi sentence\n",
    "# input_ids = tokenizer(\n",
    "#     'भारतीय राष्ट्रीय कांग्रेस के अध्यक्ष राहुल गांधी ने शनिवार को कहा कि भारतीय जनता पार्टी ने देश को एक दशक में वापस ले जाया है।',\n",
    "#     return_tensors=\"pt\",\n",
    "# ).input_ids\n",
    "\n",
    "# labels = tokenizer(\n",
    "#     'राहुल गांधी ने कहा कि भारतीय जनता पार्टी ने देश को एक दशक में वापस ले जाया है।', return_tensors=\"pt\",\n",
    "# ).input_ids\n",
    "\n",
    "# # the forward function automatically creates the correct decoder_input_ids\n",
    "# outputs = model(input_ids=input_ids, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = model.generate(input_ids, decoder_start_token_id=model.config.decoder_start_token_id)\n",
    "# outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer2 = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "# tokenizer2.decode(outputs[0], skip_special_tokens=True, predict_with_generate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21225, 4) (3000, 3)\n",
      "(18041, 4) (3184, 4) (3000, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df = pd.read_csv('/mnt/disk1/sumdev/CourseWork/NLP/NLP-Project/Data/hindi_train.csv')\n",
    "test_df = pd.read_csv('/mnt/disk1/sumdev/CourseWork/NLP/NLP-Project/Data/HindiNews_test.csv')\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "train_val_split = 0.15\n",
    "train_df, val_df = train_test_split(train_df, test_size=train_val_split, random_state=42)\n",
    "print(train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8713</th>\n",
       "      <td>hindi_2023_train_8713</td>\n",
       "      <td>प्रोडक्शन के लिए एम्ब्रेयर और सुखोई की बातचीत ...</td>\n",
       "      <td>india looks partner sukhoi embraer to manufact...</td>\n",
       "      <td>भारत सरकार दूर-दराज इलाकों से बेहतर एयर कनेक्ट...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19043</th>\n",
       "      <td>hindi_2022_9186</td>\n",
       "      <td>UP: भदोही में नशे में धुत युवक ने महात्मा गांध...</td>\n",
       "      <td>जिसके बाद कांग्रेस कार्यकर्ता एकत्रित होकर गां...</td>\n",
       "      <td>भदोहीः उत्तर प्रदेश के भदोही में बीती शनिवार र...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17257</th>\n",
       "      <td>hindi_2022_7400</td>\n",
       "      <td>भारत के इस क्षेत्र में नहीं है Coronavirus का ...</td>\n",
       "      <td>भारत में कोविड-19 के मामले 97.35 लाख के पार चल...</td>\n",
       "      <td>कोच्चि: भारत में कोविड-19 के मामले 97.35 लाख क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>hindi_2023_train_3156</td>\n",
       "      <td>12वीं में पासिंग परसेंटेज के आधार पर परीक्षा म...</td>\n",
       "      <td>NEET 2024 - No Minimum Marks Needed For NEET. ...</td>\n",
       "      <td>12वीं के बाद मेडिकल की पढ़ाई करने वाले छात्रों ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15583</th>\n",
       "      <td>hindi_2022_5726</td>\n",
       "      <td>उत्तर प्रदेश में कोरोना वायरस से 17 और मौतें, ...</td>\n",
       "      <td>उत्‍तर प्रदेश में शुक्रवार को कोरोना वायरस संक...</td>\n",
       "      <td>लखनऊ: उत्‍तर प्रदेश में शुक्रवार को कोरोना वाय...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Id  \\\n",
       "8713   hindi_2023_train_8713   \n",
       "19043        hindi_2022_9186   \n",
       "17257        hindi_2022_7400   \n",
       "3156   hindi_2023_train_3156   \n",
       "15583        hindi_2022_5726   \n",
       "\n",
       "                                                 Heading  \\\n",
       "8713   प्रोडक्शन के लिए एम्ब्रेयर और सुखोई की बातचीत ...   \n",
       "19043  UP: भदोही में नशे में धुत युवक ने महात्मा गांध...   \n",
       "17257  भारत के इस क्षेत्र में नहीं है Coronavirus का ...   \n",
       "3156   12वीं में पासिंग परसेंटेज के आधार पर परीक्षा म...   \n",
       "15583  उत्तर प्रदेश में कोरोना वायरस से 17 और मौतें, ...   \n",
       "\n",
       "                                                 Summary  \\\n",
       "8713   india looks partner sukhoi embraer to manufact...   \n",
       "19043  जिसके बाद कांग्रेस कार्यकर्ता एकत्रित होकर गां...   \n",
       "17257  भारत में कोविड-19 के मामले 97.35 लाख के पार चल...   \n",
       "3156   NEET 2024 - No Minimum Marks Needed For NEET. ...   \n",
       "15583  उत्‍तर प्रदेश में शुक्रवार को कोरोना वायरस संक...   \n",
       "\n",
       "                                                 Article  \n",
       "8713   भारत सरकार दूर-दराज इलाकों से बेहतर एयर कनेक्ट...  \n",
       "19043  भदोहीः उत्तर प्रदेश के भदोही में बीती शनिवार र...  \n",
       "17257  कोच्चि: भारत में कोविड-19 के मामले 97.35 लाख क...  \n",
       "3156   12वीं के बाद मेडिकल की पढ़ाई करने वाले छात्रों ...  \n",
       "15583  लखनऊ: उत्‍तर प्रदेश में शुक्रवार को कोरोना वाय...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForCausalLM were not initialized from the model checkpoint at monsoon-nlp/hindi-bert and are newly initialized: ['electra.encoder.layer.0.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.0.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.0.crossattention.output.dense.bias', 'electra.encoder.layer.0.crossattention.output.dense.weight', 'electra.encoder.layer.0.crossattention.self.key.bias', 'electra.encoder.layer.0.crossattention.self.key.weight', 'electra.encoder.layer.0.crossattention.self.query.bias', 'electra.encoder.layer.0.crossattention.self.query.weight', 'electra.encoder.layer.0.crossattention.self.value.bias', 'electra.encoder.layer.0.crossattention.self.value.weight', 'electra.encoder.layer.1.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.1.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.1.crossattention.output.dense.bias', 'electra.encoder.layer.1.crossattention.output.dense.weight', 'electra.encoder.layer.1.crossattention.self.key.bias', 'electra.encoder.layer.1.crossattention.self.key.weight', 'electra.encoder.layer.1.crossattention.self.query.bias', 'electra.encoder.layer.1.crossattention.self.query.weight', 'electra.encoder.layer.1.crossattention.self.value.bias', 'electra.encoder.layer.1.crossattention.self.value.weight', 'electra.encoder.layer.10.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.10.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.10.crossattention.output.dense.bias', 'electra.encoder.layer.10.crossattention.output.dense.weight', 'electra.encoder.layer.10.crossattention.self.key.bias', 'electra.encoder.layer.10.crossattention.self.key.weight', 'electra.encoder.layer.10.crossattention.self.query.bias', 'electra.encoder.layer.10.crossattention.self.query.weight', 'electra.encoder.layer.10.crossattention.self.value.bias', 'electra.encoder.layer.10.crossattention.self.value.weight', 'electra.encoder.layer.11.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.11.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.11.crossattention.output.dense.bias', 'electra.encoder.layer.11.crossattention.output.dense.weight', 'electra.encoder.layer.11.crossattention.self.key.bias', 'electra.encoder.layer.11.crossattention.self.key.weight', 'electra.encoder.layer.11.crossattention.self.query.bias', 'electra.encoder.layer.11.crossattention.self.query.weight', 'electra.encoder.layer.11.crossattention.self.value.bias', 'electra.encoder.layer.11.crossattention.self.value.weight', 'electra.encoder.layer.2.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.2.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.2.crossattention.output.dense.bias', 'electra.encoder.layer.2.crossattention.output.dense.weight', 'electra.encoder.layer.2.crossattention.self.key.bias', 'electra.encoder.layer.2.crossattention.self.key.weight', 'electra.encoder.layer.2.crossattention.self.query.bias', 'electra.encoder.layer.2.crossattention.self.query.weight', 'electra.encoder.layer.2.crossattention.self.value.bias', 'electra.encoder.layer.2.crossattention.self.value.weight', 'electra.encoder.layer.3.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.3.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.3.crossattention.output.dense.bias', 'electra.encoder.layer.3.crossattention.output.dense.weight', 'electra.encoder.layer.3.crossattention.self.key.bias', 'electra.encoder.layer.3.crossattention.self.key.weight', 'electra.encoder.layer.3.crossattention.self.query.bias', 'electra.encoder.layer.3.crossattention.self.query.weight', 'electra.encoder.layer.3.crossattention.self.value.bias', 'electra.encoder.layer.3.crossattention.self.value.weight', 'electra.encoder.layer.4.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.4.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.4.crossattention.output.dense.bias', 'electra.encoder.layer.4.crossattention.output.dense.weight', 'electra.encoder.layer.4.crossattention.self.key.bias', 'electra.encoder.layer.4.crossattention.self.key.weight', 'electra.encoder.layer.4.crossattention.self.query.bias', 'electra.encoder.layer.4.crossattention.self.query.weight', 'electra.encoder.layer.4.crossattention.self.value.bias', 'electra.encoder.layer.4.crossattention.self.value.weight', 'electra.encoder.layer.5.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.5.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.5.crossattention.output.dense.bias', 'electra.encoder.layer.5.crossattention.output.dense.weight', 'electra.encoder.layer.5.crossattention.self.key.bias', 'electra.encoder.layer.5.crossattention.self.key.weight', 'electra.encoder.layer.5.crossattention.self.query.bias', 'electra.encoder.layer.5.crossattention.self.query.weight', 'electra.encoder.layer.5.crossattention.self.value.bias', 'electra.encoder.layer.5.crossattention.self.value.weight', 'electra.encoder.layer.6.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.6.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.6.crossattention.output.dense.bias', 'electra.encoder.layer.6.crossattention.output.dense.weight', 'electra.encoder.layer.6.crossattention.self.key.bias', 'electra.encoder.layer.6.crossattention.self.key.weight', 'electra.encoder.layer.6.crossattention.self.query.bias', 'electra.encoder.layer.6.crossattention.self.query.weight', 'electra.encoder.layer.6.crossattention.self.value.bias', 'electra.encoder.layer.6.crossattention.self.value.weight', 'electra.encoder.layer.7.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.7.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.7.crossattention.output.dense.bias', 'electra.encoder.layer.7.crossattention.output.dense.weight', 'electra.encoder.layer.7.crossattention.self.key.bias', 'electra.encoder.layer.7.crossattention.self.key.weight', 'electra.encoder.layer.7.crossattention.self.query.bias', 'electra.encoder.layer.7.crossattention.self.query.weight', 'electra.encoder.layer.7.crossattention.self.value.bias', 'electra.encoder.layer.7.crossattention.self.value.weight', 'electra.encoder.layer.8.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.8.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.8.crossattention.output.dense.bias', 'electra.encoder.layer.8.crossattention.output.dense.weight', 'electra.encoder.layer.8.crossattention.self.key.bias', 'electra.encoder.layer.8.crossattention.self.key.weight', 'electra.encoder.layer.8.crossattention.self.query.bias', 'electra.encoder.layer.8.crossattention.self.query.weight', 'electra.encoder.layer.8.crossattention.self.value.bias', 'electra.encoder.layer.8.crossattention.self.value.weight', 'electra.encoder.layer.9.crossattention.output.LayerNorm.bias', 'electra.encoder.layer.9.crossattention.output.LayerNorm.weight', 'electra.encoder.layer.9.crossattention.output.dense.bias', 'electra.encoder.layer.9.crossattention.output.dense.weight', 'electra.encoder.layer.9.crossattention.self.key.bias', 'electra.encoder.layer.9.crossattention.self.key.weight', 'electra.encoder.layer.9.crossattention.self.query.bias', 'electra.encoder.layer.9.crossattention.self.query.weight', 'electra.encoder.layer.9.crossattention.self.value.bias', 'electra.encoder.layer.9.crossattention.self.value.weight', 'generator_lm_head.bias', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias', 'generator_predictions.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import EncoderDecoderModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"monsoon-nlp/hindi-bert\")\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"monsoon-nlp/hindi-bert\", \"gpt2\")\n",
    "\n",
    "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/sumdev/CourseWork/a3_env/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:616: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "/mnt/disk1/sumdev/CourseWork/a3_env/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:636: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000 Loss: 7.803432563304901\n",
      "Batch 2000 Loss: 7.540177937030792\n",
      "Batch 3000 Loss: 7.524164014339447\n",
      "Batch 4000 Loss: 7.456521791934967\n",
      "Batch 5000 Loss: 7.468214980602264\n",
      "Batch 6000 Loss: 7.430041268348694\n",
      "Batch 7000 Loss: 7.421582843780517\n",
      "Batch 8000 Loss: 7.435788701534271\n",
      "Batch 9000 Loss: 7.451207971572876\n",
      "Batch 10000 Loss: 7.413762616634369\n",
      "Batch 11000 Loss: 7.4254929637908935\n",
      "Batch 12000 Loss: 7.4491350345611576\n",
      "Batch 13000 Loss: 7.52306252002716\n",
      "Batch 14000 Loss: 7.412403644084931\n",
      "Batch 15000 Loss: 7.413734418392181\n",
      "Batch 16000 Loss: 7.399366858005524\n",
      "Batch 17000 Loss: 7.397126619815826\n",
      "Batch 18000 Loss: 7.415912605762482\n",
      "Training Loss: 7.465806795312338\n",
      "Validation Loss: 7.419983010046447\n",
      "Epoch 2\n",
      "Batch 1000 Loss: 7.290245727539062\n",
      "Batch 2000 Loss: 7.332596723079681\n",
      "Batch 3000 Loss: 7.371773745059967\n",
      "Batch 4000 Loss: 7.33793325138092\n",
      "Batch 5000 Loss: 7.3714003348350525\n",
      "Batch 6000 Loss: 7.336872177600861\n",
      "Batch 7000 Loss: 7.335406280517578\n",
      "Batch 8000 Loss: 7.344756159305573\n",
      "Batch 9000 Loss: 7.371088516235352\n",
      "Batch 10000 Loss: 7.335907151699066\n",
      "Batch 11000 Loss: 7.352101456165314\n",
      "Batch 12000 Loss: 7.365818056583405\n",
      "Batch 13000 Loss: 7.36556854391098\n",
      "Batch 14000 Loss: 7.351004422187805\n",
      "Batch 15000 Loss: 7.359743026256561\n",
      "Batch 16000 Loss: 7.358899189472199\n",
      "Batch 17000 Loss: 7.358777588367462\n",
      "Batch 18000 Loss: 7.38075692653656\n",
      "Training Loss: 7.351522484109021\n",
      "Validation Loss: 7.432590309249695\n",
      "Epoch 3\n",
      "Batch 1000 Loss: 7.254461503028869\n",
      "Batch 2000 Loss: 7.302683922767639\n",
      "Batch 3000 Loss: 7.341724457263947\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     evaluate(model, tokenizer, val_df)\n",
      "Cell \u001b[0;32mIn[60], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, tokenizer, train_df, optimizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     13\u001b[0m batch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/CourseWork/a3_env/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CourseWork/a3_env/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(model, tokenizer, train_df, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    batch = 0\n",
    "    batch_loss = 0\n",
    "    batch_size = 1000\n",
    "    for i, row in train_df.iterrows():\n",
    "        input_ids = tokenizer(row['Heading'], return_tensors=\"pt\").input_ids.to(device)\n",
    "        labels = tokenizer(row['Summary'], return_tensors=\"pt\").input_ids.to(device)\n",
    "        outputs = model(input_ids=input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        batch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        batch += 1\n",
    "        if batch % batch_size == 0:\n",
    "            print(f\"Batch {batch} Loss: {batch_loss / batch_size}\")\n",
    "            batch_loss = 0\n",
    "    print(f\"Training Loss: {total_loss / len(train_df)}\")\n",
    "        \n",
    "\n",
    "def evaluate(model, tokenizer, val_df):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for i, row in val_df.iterrows():\n",
    "        input_ids = tokenizer(row['Heading'], return_tensors=\"pt\").input_ids.to(device)\n",
    "        labels = tokenizer(row['Summary'], return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, labels=labels)\n",
    "        total_loss += outputs.loss.item()\n",
    "    print(f\"Validation Loss: {total_loss / len(val_df)}\")\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    train(model, tokenizer, train_df, optimizer)\n",
    "    evaluate(model, tokenizer, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HindiNews_test_6\n",
      "साल-दर-साल बढ़ती गर्मी के चलते देश की खेती, अर्थव्यवस्था और लोगों के स्वास्थ्य पर बहुत दबाव पड़ रहा है। वहीं, जलवायु परिवर्तन की वजह से गरीबी, असमानता और बीमारियों को खत्म करने के देश की कोशिशें भी नाकाम हो रही हैं। यह खुलासा कैंब्रिज यूनिवर्सिटी की एक नई स्टडी में हुआ है। इसे स्कॉलर्स की एक टीम ने पब्लिश किया है।\n",
      "टीम के लीडर रमित देबनाथ ने कहा कि लू के चलते 1992 से अब तक देश में 24 हजार से ज्यादा मौतें दर्ज हुई हैं। गर्मी के चलते वायु प्रदूषण बढ़ गया है और उत्तर भारत के पहाड़ों में मौजूद ग्लेशियर पिघलने लगे हैं। देश में जनवरी से अक्टूबर तक तकरीबन हर रोज भीषण मौसम देखने को मिल रहा है, जिसकी वजह से देश को एक साथ कई सारी मौसमी परेशानियों का सामना करना पड़ सकता है।\n",
      "देश का 90% इलाका हीट जोन बना \n",
      "देबनाथ ने रॉयटर्स को बताया कि लगभग भारत के कुल एरिया में से 90% गंभीर हीट जोन बन चुके हैं और ये इस गर्मी से निपटने से के लिए तैयार नहीं हैं। उन्होंने कहा कि भारत ने लू को अपने डिजास्टर रिलीफ पैकेज में शामिल किया है, लेकिन इन योजनाओं की रफ्तार को तेज करने की जरूरत है।\n",
      "भीषण गर्मी के चलते GDP को नुकसान\n",
      "रिसर्चर्स ने यह चेतावनी भी दी कि भीषण गर्मी के चलते खुले में काम करने की लोगों की क्षमता 15% तक कम हो सकती है, करीब 48 लाख लोगों की जीवन की गुणवत्ता का स्तर गिर सकता है और 2050 तक GDP का 2.8% का नुकसान हो सकता है।\n",
      "torch.Size([1, 295])\n",
      "tensor([[    3,  9346, 27915, 27915, 36895, 27915, 27915, 27915, 15641, 31123,\n",
      "         31123,  2317, 27915, 15641, 27915, 39621,  2317,  2317,  2317,  2317]],\n",
      "       device='cuda:0')\n",
      "Summary: ##ore चिपच चिपच उष चिपच चिपच चिपचीता नगा नगाीत चिपचीता चिपचिबरीतीतीतीत\n"
     ]
    }
   ],
   "source": [
    "text = test_df['Article'][6]\n",
    "print(test_df['id'][6])\n",
    "print(text)\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\", truncation=True).input_ids.to(device)\n",
    "print(input_ids.shape)\n",
    "\n",
    "outputs = model.generate(input_ids, decoder_start_token_id=model.config.decoder_start_token_id)\n",
    "print(outputs)\n",
    "# tokenizer2\n",
    "summary = tokenizer.decode(outputs[0], skip_special_tokens=True, predict_with_generate=True)\n",
    "print(\"Summary:\", summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
